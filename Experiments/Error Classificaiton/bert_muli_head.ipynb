{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "error-mh.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2VFdKnUlv1iT"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFvFcJ18PcIf"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUZ2Yw0ePjsX"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.optim import AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn.functional as F\n",
        "# from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "# from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
        "\n",
        "from tqdm import tqdm , trange\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel, BertTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbPc9xrDVcrf",
        "outputId": "87b754a9-cd2f-4ac8-a6b7-c4df747fe8ea"
      },
      "source": [
        "import pandas as pd\n",
        "!git clone https://gitlab.com/vibss2397/nlp.git\n",
        "df = pd.read_csv(\"nlp/fce_old.csv\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'nlp'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 35 (delta 12), reused 0 (delta 0), pack-reused 0\n",
            "Unpacking objects: 100% (35/35), done.\n",
            "Checking out files: 100% (7/7), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VFdKnUlv1iT"
      },
      "source": [
        "# Data Processing Old"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpSzVIq3013X"
      },
      "source": [
        "!ls nlp"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42Yf-uV6YqH9"
      },
      "source": [
        "df1 = df[['incorrect', 'err_type']]\n",
        "df1 = df1.rename(columns={'incorrect':'input','err_type':'err'})\n",
        "\n",
        "df2 = df[['correct']]\n",
        "df2.insert(1, 'err', 'CO')\n",
        "df2 = df2.rename(columns={'correct':'input','err':'err'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzQy-6UJu_E3"
      },
      "source": [
        "frames = [df1, df2]\n",
        "result = pd.concat(frames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52SEvBvh7z7I",
        "outputId": "29b77485-bfa7-47e3-db54-b3e70e6f1327"
      },
      "source": [
        "result.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(89044, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtwtA9pnZFuJ"
      },
      "source": [
        "df3 = result.groupby(by='input')['err'].unique().apply(lambda x: ','.join(x)).reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5qF0myInmNC"
      },
      "source": [
        "df3['err'] = df3.err.str.split(',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mit0DPLIMnq"
      },
      "source": [
        "def remove_arr(arr, ele):\n",
        "  if ele in arr:\n",
        "    arr.remove(ele)\n",
        "  return arr\n",
        "\n",
        "df3['err'] = df3['err'].apply((lambda x: ['CO'] if 'CO' in x else x))\n",
        "df3['err'] = df3['err'].apply(lambda x: remove_arr(x, 'DS')).apply(lambda x: remove_arr(x, 'SM'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dtt4xrWr7h2e",
        "outputId": "0e5b328f-d447-40a5-d339-9c093763e0a9"
      },
      "source": [
        "df3.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17873, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4udTU-phNXi1"
      },
      "source": [
        "df3_final = df3[df3['err'].apply(lambda x: len(x)!=0)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CrWSrZXXRdd"
      },
      "source": [
        "err_categories = sorted(['LX', 'OT', 'GM', 'CO'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWJTP57CnxeL"
      },
      "source": [
        "for err_type in err_categories:\n",
        "  df3_final[err_type] = 0"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJOITIOteyWg"
      },
      "source": [
        "def make_1(row):\n",
        "  for ele in row[1]:\n",
        "    row[2 + err_categories.index(ele)] = 1\n",
        "  return row\n",
        "df3_final = df3_final.apply(make_1, axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtPH44zPkGfh",
        "outputId": "bb2e153f-aba7-48e8-d496-caf237044be7"
      },
      "source": [
        "df3_final.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17833, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZH2m885kWsV"
      },
      "source": [
        "df4 = df3_final.drop('err', axis = 1)\n",
        "# df4.to_csv('processed_fce.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5Ul-7bkwdTp"
      },
      "source": [
        "# New Data Processing\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yO_J92IXlVzp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "85481030-9061-4de7-8acc-3c27e9e522b9"
      },
      "source": [
        "df4 = pd.read_csv('nlp/fce_final.csv')\r\n",
        "df4.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>He completed B.Sc.</td>\n",
              "      <td>[1 0 0 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>He completed his M.Phil in Gujarati literature...</td>\n",
              "      <td>[1 0 0 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>He was appointed as Governor of Gujarat in 1954.</td>\n",
              "      <td>[1 0 0 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Shiva temple 3.</td>\n",
              "      <td>[1 0 0 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4 in 1984.</td>\n",
              "      <td>[1 0 0 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                                  0          1\n",
              "0           0                                 He completed B.Sc.  [1 0 0 0]\n",
              "1           1  He completed his M.Phil in Gujarati literature...  [1 0 0 0]\n",
              "2           2   He was appointed as Governor of Gujarat in 1954.  [1 0 0 0]\n",
              "3           3                                    Shiva temple 3.  [1 0 0 0]\n",
              "4           4                                         4 in 1984.  [1 0 0 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbWvAUQsAe1U"
      },
      "source": [
        "#selecting sentence and labels\r\n",
        "df4 = df4[['0', '1']]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yZ6G1ugmFTa"
      },
      "source": [
        "# Finding the length of the biggest sentence\n",
        "df4['len'] = df4.apply(lambda x: len(x[0].split(' ')), axis=1)\n",
        "df5 = df4[['0', 'len']]\n",
        "df5_numpy = df5.to_numpy()\n",
        "max_len = ['', float('-inf')]\n",
        "for ele in df5_numpy:\n",
        "  if(ele[1]>max_len[1]):\n",
        "    max_len[0] = ele[0]\n",
        "    max_len[1] = ele[1]\n",
        "df4 = df4.drop('len', axis=1)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKSnrzFVHIJt",
        "outputId": "60b1e7f9-e7d3-4fae-f47d-63fa65eed1c3"
      },
      "source": [
        "max_len"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Today I have to tell you something really exciting and also very hard to believe. Last month I received a letter which told me that I\\'d enteredI\\'d won a competition. I was so happy and surprised that first I could not really believe it.  But it was true. My prize was the chance to meet a pop group and to help at their concert. The pop group which was going to play is called \"Metallica\" and I like their music very much (\\'cause in my opinion the music is a bit different from all the songs you usually listen to). But now to the concert itself. It took place on the 10th of June in Salzburg. It started at 8 pm but I had to be there at 11 am. First I had to help with the catering, which lasted until 2 pm. After this I met the band members and got to know them while we were having a good meal. The front man felt a bit sick and so he skipped the meal. I was so excited that I was not able to eat anything either. At 5 pm the band members disappeared again and I was responsible for some kind of guided tour for the journalists. I had to show them the way to the interviewing room. It was a bit boring but more or less okay. At 7 p.m. the first group started. They were unknown and not very good but when I met them afterwards I realised that they were very nice. At 8 pm Metallica started and, I have to tell you, they gave a great performance. When I met them after the concert they asked me questions like \"Did you like the performance?\" or \"What do you think about the first group?\" Questions like you and I usually ask each other. You know what I mean.  They were not conceited or anything like that. They were like  other personspeople and I have to admit that I like them very much. This was one of the best and most exciting days of my life.',\n",
              " 353]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4y4ADEkHnOI",
        "outputId": "57453aab-e187-4317-c2b2-c47ad8ae47e9"
      },
      "source": [
        "# Splitting into train/test dataset\n",
        "train_data = df4.sample(frac=0.80, random_state=0)\n",
        "test_data = df4.drop(train_data.index)\n",
        "train_arr = np.array(train_data)\n",
        "test_arr = np.array(test_data)\n",
        "print(\"Train shape\", train_arr.shape)\n",
        "print(\"Test shape\", test_arr.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train shape (24578, 2)\n",
            "Test shape (6145, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gxoVtynIOv_"
      },
      "source": [
        "# csv contains label array but array is a string(eg : '[0, 1, 0, 0]'), converting string back to arr.\r\n",
        "final_train_arr = []\r\n",
        "for ele in train_arr:\r\n",
        "  final_train_arr.append([ele[0], np.array([int(a) for a in ele[1][1:-1].split(' ')])])\r\n",
        "final_test_arr = []\r\n",
        "for ele in test_arr:\r\n",
        "  final_test_arr.append([ele[0], np.array([int(a) for a in ele[1][1:-1].split(' ')])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkNsiDbIKm91"
      },
      "source": [
        "train_data = pd.DataFrame(final_train_arr)\r\n",
        "test_data = pd.DataFrame(final_test_arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASLOHie84rHg",
        "outputId": "ac13f9d4-580e-4711-d0ea-f91314c8cae7"
      },
      "source": [
        "# weights for weighted loss.\n",
        "weights = np.sum(train_data[1])\n",
        "weights_sum = np.sum(weights)\n",
        "weights2 = weights_sum/weights\n",
        "weights2 = weights2/weights2[0]\n",
        "# weights2 = np.exp(weights2)/sum(np.exp(weights2))\n",
        "print(weights2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.         3.47405299 2.08598475 4.26964478]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3o7s9LkI0r-"
      },
      "source": [
        "class CustomBERTModel(nn.Module):\n",
        "    def __init__(self, n_heads = 4, last_layer_unfreeze = False):\n",
        "          super(CustomBERTModel, self).__init__()\n",
        "          self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "          for name, param in self.bert.named_parameters():\n",
        "            if(last_layer_unfreeze):\n",
        "              if(name.find('pooler')>=0 or name.find('11')>=0 or name.find('10')>=0):\n",
        "                param.requires_grad = True\n",
        "              else:\n",
        "                param.requires_grad = False\n",
        "            else:\n",
        "              param.requires_grad = True\n",
        "\n",
        "          self.dropout = nn.Dropout(0.5)\n",
        "          self.out1 = nn.Linear(768, 1)\n",
        "          self.out2 = nn.Linear(768, 1)\n",
        "          self.out3 = nn.Linear(768, 1)\n",
        "          self.out4 = nn.Linear(768, 1)\n",
        "    def forward(self, input_ids, token_type_ids, attention_mask):\n",
        "          pooled_output = self.bert(\n",
        "               input_ids, \n",
        "               attention_mask,\n",
        "               token_type_ids\n",
        "          )\n",
        "          out1 = self.out1(pooled_output[1])\n",
        "          \n",
        "          out2 = self.out2(pooled_output[1])\n",
        "          \n",
        "          out3 = self.out3(pooled_output[1])\n",
        "\n",
        "          out4 = self.out4(pooled_output[1])\n",
        "          return out1, out2, out3, out4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNhLowlqQncj"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "bert_model = CustomBERTModel().to(device)\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pE-DrPeMQGuo",
        "outputId": "6e59e897-9f62-4ed7-c0c7-fbe081c2abc2"
      },
      "source": [
        "# uses pretrained weights in the nlp repository downloaded above.\r\n",
        "bert_model.load_state_dict(torch.load('nlp/final/bert-model-mh3.pth'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I60cUd8mbgX8"
      },
      "source": [
        "# Creating Custom Dataset\n",
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, targets, max_len):\n",
        "        self.data = data\n",
        "        self.targets = targets\n",
        "        self.max_len = max_len\n",
        "    def __getitem__(self, index):\n",
        "        if torch.is_tensor(index):\n",
        "            index = index.tolist()\n",
        "        x = self.data[index]\n",
        "        label = torch.tensor(self.targets[index], dtype=torch.float)\n",
        "        return [x, label]\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9sYwWXdQ3IR"
      },
      "source": [
        "# Tokenizer encoding\n",
        "def encode_sentence(sentence, max_len):\n",
        "    return bert_tokenizer.batch_encode_plus(\n",
        "                        sentence,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = max_len,           # Pad & truncate all sentences.\n",
        "                        padding = 'max_length',\n",
        "                        truncation = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt'    # Return pytorch tensors.\n",
        "                   )\n",
        "# converting arr to dataset\n",
        "train_dataset = MyDataset(train_data[0], train_data[1], max_len[1])\n",
        "\n",
        "# 50% of test arr is validation dataset, rest is test\n",
        "validation_dataset = MyDataset(test_data[0].to_numpy()[:len(test_data[0])//2], \n",
        "                               test_data[1].to_numpy()[:len(test_data[0])//2], max_len[1])\n",
        "\n",
        "test_dataset = MyDataset(test_data[0].to_numpy()[len(test_data[0])//2:], \n",
        "                               test_data[1].to_numpy()[len(test_data[0])//2:], max_len[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRzhogA9SHFL"
      },
      "source": [
        "bs = 16\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            shuffle = True,\n",
        "            batch_size = bs # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            validation_dataset,  # The training samples.\n",
        "            sampler = SequentialSampler(validation_dataset), # Select batches sequentially\n",
        "            batch_size = bs # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "            test_dataset,  # The training samples.\n",
        "            sampler = SequentialSampler(test_dataset), # Sequentially\n",
        "            batch_size = bs # Trains with this batch size.\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emPq2FgA1I06"
      },
      "source": [
        "optimizer = AdamW([\n",
        "                   {'params': bert_model.bert.parameters(), 'lr': 2e-5},\n",
        "                   {'params': bert_model.out1.parameters(), 'lr': 1e-4},\n",
        "                   {'params': bert_model.out2.parameters(), 'lr': 1e-4},\n",
        "                   {'params': bert_model.out3.parameters(), 'lr': 1e-4},\n",
        "                   {'params': bert_model.out4.parameters(), 'lr': 1e-4},\n",
        "                   ],\n",
        "                  weight_decay=1,\n",
        "                  eps = 1e-8, # args.adam_epsilon  - default is 1e-8.\n",
        "                   )\n",
        "# Separate loss function with different weights for each error class.\n",
        "loss = [nn.BCEWithLogitsLoss(reduction = 'sum', pos_weight=torch.tensor(weights2[0])), nn.BCEWithLogitsLoss(reduction = 'sum', pos_weight=torch.tensor(weights2[1])), \n",
        "         nn.BCEWithLogitsLoss(reduction = 'sum', pos_weight=torch.tensor(weights2[2])), nn.BCEWithLogitsLoss(reduction = 'sum', pos_weight=torch.tensor(weights2[3]))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ma4uaKuB0K4m"
      },
      "source": [
        "# Run this if you want to train a new model.\n",
        "epochs = 5\n",
        "MAX_LEN = max_len[1]\n",
        "for epoch_i in range(0, epochs):\n",
        "    # Running BERT model on train dataset.\n",
        "    train_loss = [0, 0]\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if step % 100 == 0 and not step == 0:\n",
        "            print('  Batch {:>5,}  of  {:>5,} Loss {:>5,}.'.format(step, len(train_dataloader), train_loss[0]/train_loss[1]))\n",
        "        inputs = batch[0]\n",
        "        labels = batch[1]\n",
        "        inputs_encoded = encode_sentence(inputs, MAX_LEN)\n",
        "        for ele in inputs_encoded:\n",
        "            inputs_encoded[ele] = inputs_encoded[ele].to(device)\n",
        "        inputs_encoded['token_type_ids'] = None\n",
        "\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits_arr = bert_model(**inputs_encoded)\n",
        "        \n",
        "        curr_batch_size = labels.size()[0]\n",
        "        curr_loss = 0\n",
        "        for i in range(len(logits_arr)):\n",
        "          curr_loss+= loss[i](logits_arr[i], labels[:, i].reshape(curr_batch_size, 1))\n",
        "        curr_loss.backward()\n",
        "        train_loss[0]+= curr_loss.data.cpu().item()\n",
        "        train_loss[1]+= curr_batch_size\n",
        "        optimizer.step()\n",
        "    print('Training Loss is : %f'%(train_loss[0]/train_loss[1]))\n",
        "    # Running BERT model on validation dataset.\n",
        "    bert_model.eval()\n",
        "    val_loss = [0, 0]\n",
        "    for step, batch in enumerate(validation_dataloader):\n",
        "        inputs = batch[0]\n",
        "        labels = batch[1]\n",
        "        inputs_encoded = encode_sentence(inputs, MAX_LEN)\n",
        "        for ele in inputs_encoded:\n",
        "            inputs_encoded[ele] = inputs_encoded[ele].to(device)\n",
        "        inputs_encoded['token_type_ids'] = None\n",
        "        labels = labels.to(device)\n",
        "        with torch.no_grad():\n",
        "            logits_arr = bert_model(**inputs_encoded)\n",
        "            curr_batch_size = labels.size()[0]\n",
        "            curr_loss = 0\n",
        "            for i in range(len(logits_arr)):\n",
        "              curr_loss+= loss[i](logits_arr[i], labels[:, i].reshape(curr_batch_size, 1))\n",
        "            val_loss[0]+= curr_loss.data.cpu().item()\n",
        "            val_loss[1]+= curr_batch_size\n",
        "    bert_model.train()\n",
        "    print('Validation Loss is : %f'%(val_loss[0]/val_loss[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2Niuuu9R2Rl"
      },
      "source": [
        "# model = torch.load(MODEL_LOAD_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzDhjF9FR6mD",
        "outputId": "db22629c-d50f-4cbf-9006-d0585114e475"
      },
      "source": [
        "# Getting statistics on Test set\n",
        "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
        "err_label = []\n",
        "err_logits = []\n",
        "bert_model.eval()\n",
        "for i, batch in enumerate(test_dataloader):\n",
        "  input = batch[0]\n",
        "  labels = batch[1]\n",
        "  inputs_encoded = encode_sentence(input, 512)\n",
        "  curr_loss = 0\n",
        "  total_batch_size = 0\n",
        "  for ele in inputs_encoded:\n",
        "      inputs_encoded[ele] = inputs_encoded[ele].to(device)\n",
        "  labels = labels.to(device)\n",
        "  with torch.no_grad():\n",
        "    logits = bert_model(**inputs_encoded)\n",
        "    logits_combined = torch.cat(logits, dim=1)\n",
        "    logits_to_labels = torch.sigmoid(logits_combined)\n",
        "  err_label.extend(labels.data.cpu().numpy())\n",
        "  err_logits.extend(logits_to_labels.data.cpu().numpy())\n",
        "  total_batch_size += labels.size()[0]\n",
        "  err_predictions = np.array(np.array(err_logits)>0.5, dtype = np.int)\n",
        "  err_labels = np.array(err_label, dtype=np.int)\n",
        "print(f1_score(err_labels, err_predictions, average='micro'))\n",
        "print(accuracy_score(err_labels, err_predictions))\n",
        "print(classification_report(err_labels, err_predictions, target_names=err_categories))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7181201255950572\n",
            "0.5421412300683371\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CO       0.70      0.90      0.79      1549\n",
            "          GM       0.59      0.72      0.65       935\n",
            "          LX       0.70      0.70      0.70      1301\n",
            "          OT       0.62      0.76      0.69       737\n",
            "\n",
            "   micro avg       0.66      0.78      0.72      4522\n",
            "   macro avg       0.65      0.77      0.71      4522\n",
            "weighted avg       0.66      0.78      0.72      4522\n",
            " samples avg       0.68      0.78      0.71      4522\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiIo00vuKQ5o"
      },
      "source": [
        "# random stuff"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkHHyqmBsfSS",
        "outputId": "b0515213-6ba8-4a3a-c536-af87e134cb56"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Nov 10 04:07:45 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P0    24W /  75W |   7551MiB /  7611MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}